{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e76SPZc1cGet",
    "outputId": "41995f0a-b2cc-4ca1-9bd0-9a7c35c3123d"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMgxXhNL3FKx"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79epoEzVXcsV",
    "outputId": "689b7eb0-f83a-4ce7-9ef9-13330af0a9e9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "\n",
    "\n",
    "# conditional image captioning\n",
    "text = \"a photography of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "# unconditional image captioning\n",
    "inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKP0uSapYEjd"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ko2sP1KFZdQK",
    "outputId": "0e30dc1b-b0c3-4a2b-84af-8aa7a056d3dc"
   },
   "outputs": [],
   "source": [
    "# unconditional image captioning\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqGgyl7vZfCD"
   },
   "outputs": [],
   "source": [
    "image2 = Image.open(requests.get('https://images.prov.vic.gov.au/loris/58%2F23%2F7C%2F38%2F-5613-11EB-BE8C-27052853D7D8%2Fimages%2F1%2Ffiles%2F14517-00028-J0596.tif/full/!1000,1000/0/default.jpg', stream=True).raw).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LONnqvcZga_",
    "outputId": "21f5a91e-af25-44e7-fac0-3e6f8520b5e4"
   },
   "outputs": [],
   "source": [
    "# unconditional image captioning\n",
    "inputs = processor(image2, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPJjBsD4tVw7",
    "outputId": "039ae500-e1c1-4654-9fc6-5d9a89a3432c"
   },
   "outputs": [],
   "source": [
    "# conditional image captioning\n",
    "text = \"\"\n",
    "inputs = processor(image2, text, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnB_QEmPtegr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "tfHn9IFjsEHt",
    "outputId": "5a485e7a-9527-40aa-b803-f62f73e0df34"
   },
   "outputs": [],
   "source": [
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9ybjhJ3Zm-x"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak6k7VKrf9hh"
   },
   "outputs": [],
   "source": [
    "with open('/content/14517_100.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca2298EaiV15",
    "outputId": "da0a3fde-0736-4364-f227-7752d36a5a04"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCs2KF-Wip1-",
    "outputId": "3f3945b8-1937-4661-b6c2-c9dd13d51d88"
   },
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "6bYJpy2wjATM",
    "outputId": "bb3a25f5-99ab-43f4-c089-01242d3c0b5e"
   },
   "outputs": [],
   "source": [
    "data[1]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vwLa4F4jrqQK",
    "outputId": "3c55dfca-f955-4059-e953-0f2fda7afedb"
   },
   "outputs": [],
   "source": [
    "data[0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwg-d3lAruzG",
    "outputId": "859fbea7-e042-49c7-fb97-13159def369b"
   },
   "outputs": [],
   "source": [
    "for i in data:\n",
    "  print(i['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250,
     "referenced_widgets": [
      "49cf944c3b4a49128cb884211331e0de",
      "9ca360b1c9c04b9cafa4e813bc79a267",
      "ff5e49cd30b84308b341b0ba8003bd26",
      "e038cb4d878f4179be80f883889e5b2e",
      "00b9886d7cc84f9eada33cd89dac213d",
      "c8b37a262d43459ea7c19165ac550559",
      "e84c3907283c4e11bed139fe9c42ea38",
      "18955449924f43b69b9396f4c7ecd3ec",
      "0e9166c488014e22b8eff1e7f739ef70",
      "a07e0d62af20468da3eeb0edc8a997e8",
      "3f1858be860f42c5afeb5c79b7daaaa3",
      "1eaa20db86cc48d38502b4ffa2a70bcb",
      "62f63358498549158505a92e9ad0f5f2",
      "468d44ba294f47049e771c997322b3e9",
      "3ebfde28e60b4f66aaf466d904682358",
      "a00650acc8d64b2c8eb875650821b92e",
      "a6bd2bc4502645bc9af445a1e23497b9",
      "db15ae059d7b433e92f3d0a3cc76fb90",
      "e6a2b5e133de435c874ed0968a769cfc",
      "1cbc8d987c344f65b6e8a58cc3f0f121",
      "f9513e7d5e624cde8a0863a23ac22ac3",
      "f0c5affd2f354c7ca1af125107e9365b",
      "e025753f93a44a92bcee2ee5027199d2",
      "5055c1005b274a18896f9a2b9a8927d7",
      "6858c6c41f9f4e6483f5539cba37cc32",
      "234ae6c18bc34d6dac7adbb3e67087ac",
      "f47cbc2210a04b20814193e804a57b36",
      "866f7055aa05482aa88aaae742fde773",
      "f598226a28ec4ba780adad1865bda1db",
      "dcee697135bc40aeaa344a72c020e5a6",
      "63a148ac16ae4d5ca071445636aac2ad",
      "9c00d0531a1d47d9977c0775e78dee01",
      "4436c11bc28f426ca826d889bb063886",
      "0c409fad93c44bb798d380838972f071",
      "061eeef320c5440a919a1e90b0b5de37",
      "0972f103cad5402f89a1bf2970bf3581",
      "116bddf97af842edb1623ff729021dfe",
      "d733ea48b5de486ba5537714f14ea1ae",
      "647b6cef6732485da302e40d684d76db",
      "9f48db691a0344b881e92bd0fce9ecb6",
      "4aad6105eba2465a921b1831ad403b9f",
      "3993db1666fd4c84a3f3acbad21a9ad3",
      "c7c559c660b44515a9be97ead05bf20c",
      "3986a39db032481a8801814cd478750d",
      "50f8ca32984849848ea8756539a558b5",
      "efb9144eaee849359840bd4554c19509",
      "092646d5cce74dadb206bcd6b9e63381",
      "64239264abb549288c521aadf904747f",
      "788c7ea064dc47e5a075e1f990a3ee33",
      "c502b08f915b4be8becf7add26a8480c",
      "48000c19bd4b4864817ca6de36f3f47d",
      "33db815221f94248be521a3f62ed846f",
      "5fa4982c2e70419d8612054e764dca46",
      "0d78864e41024d4dba553aa494ed9a0c",
      "385889ac02424b9db7a4e94196975af3"
     ]
    },
    "id": "iwHCiuMGwOVS",
    "outputId": "998be4d2-6909-453d-a556-ae90d8548df2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Generate caption using BLIP (as you did in your code)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "# Step 2: Use a text-based QA model to answer questions based on the caption\n",
    "qa_pipeline = pipeline(\"question-answering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRIf-A-L0vrz",
    "outputId": "aeb3e06c-470a-4046-d870-33499f64de1a"
   },
   "outputs": [],
   "source": [
    "question = \"Summarise in one word\"  # Example question\n",
    "context = \"there are three deer standing in a field near a shed\"  # Using the caption as the context\n",
    "\n",
    "answer = qa_pipeline({\"question\": question, \"context\": context})\n",
    "\n",
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx2kKGnB006k"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open('blip_model_zero.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Load the processor\n",
    "with open('blip_processor_zero.pkl', 'rb') as f:\n",
    "    loaded_processor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0_VJ8zI5Njh",
    "outputId": "c6f4648c-dda5-4f6d-b7c4-9a7817c38c9f"
   },
   "outputs": [],
   "source": [
    "inputs = loaded_processor(image2, return_tensors=\"pt\")\n",
    "\n",
    "out = loaded_model.generate(**inputs)\n",
    "print(loaded_processor .decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vU38RaCk5TiY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
