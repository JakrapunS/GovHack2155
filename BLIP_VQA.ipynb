{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMsWLC6kFYZs",
    "outputId": "0acf5304-578c-43f7-ff05-37df98240bbc"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YHYC5h6d4Bgj"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95JdqaI2hPBV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJipi91zFXOI",
    "outputId": "c55626d0-de91-43d3-8761-51b2541b296f"
   },
   "outputs": [],
   "source": [
    "img_url = 'https://act.accesstomemory.org/uploads/r/null/f/0/b/f0b401c2e8a9b70af1b35737850998a076da04399a8df59172d423e67bb88565/Senior_Fire_Officer_A_141.jpg'\n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "question = \"What is the color of the photo?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGVMVVu4FcYO",
    "outputId": "96a52c95-ab62-489d-b27d-4cc3785baf51"
   },
   "outputs": [],
   "source": [
    "question = \"What is the setting of the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2Iot2lLFxYn",
    "outputId": "01e53559-7659-466a-dd0b-3e870c1d0e46"
   },
   "outputs": [],
   "source": [
    "question = \"What is the objects of the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT4SgC8YGd2Z",
    "outputId": "2166bc5c-dffc-43b9-bda2-ea961fcd70c7"
   },
   "outputs": [],
   "source": [
    "question = \"What is the image all about?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXx4Z1geGnBB",
    "outputId": "23c30d41-b2a6-42d4-f81e-70662da30d93"
   },
   "outputs": [],
   "source": [
    "question = \"What is the cultural or geographics context of the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzVKeNKAHb1w",
    "outputId": "f76da6f8-8e77-4700-f92e-71bdc0cf02fa"
   },
   "outputs": [],
   "source": [
    "question = \"What is the overall composition of the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyP_CuQJHtKP",
    "outputId": "44959eba-b2a2-44df-93f9-9ef830d91b85"
   },
   "outputs": [],
   "source": [
    "question = \"What decade the image come from?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tz94BcGpL0W2",
    "outputId": "aa616994-d837-4b7c-ca3b-ae4f0d5e9665"
   },
   "outputs": [],
   "source": [
    "question = \"What is the context on image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qg2f7sStePWV",
    "outputId": "0c7bfe4a-782d-4694-e16a-26d169c4cadc"
   },
   "outputs": [],
   "source": [
    "question = \"Is there people in the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "result_human = processor.decode(out[0], skip_special_tokens=True)\n",
    "if result_human =='yes':\n",
    "  print('human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1VIOIYKeTuP"
   },
   "outputs": [],
   "source": [
    "question = \"Is there animal in the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "result_animal = processor.decode(out[0], skip_special_tokens=True)\n",
    "if result_animal =='yes':\n",
    "  print('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwXF66ETe738"
   },
   "outputs": [],
   "source": [
    "question = \"Is there building in the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "result_building = processor.decode(out[0], skip_special_tokens=True)\n",
    "if result_building =='yes':\n",
    "  print('building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kMIIkTHfDmP"
   },
   "outputs": [],
   "source": [
    "question = \"Is there vehical in the image?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "result_vehical = processor.decode(out[0], skip_special_tokens=True)\n",
    "if result_vehical =='yes':\n",
    "  print('vehical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Y_Qur76ofRIU"
   },
   "outputs": [],
   "source": [
    "def tag_generate(img_url,model_vqa,processor_vqa, q_num):\n",
    "  tag=set()\n",
    "\n",
    "  raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "  if q_num >=1 :\n",
    "    # Question 9\n",
    "    question_9 = \"Is there people in the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_9, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    result = processor_vqa.decode(out[0], skip_special_tokens=True)\n",
    "    if result == 'yes':\n",
    "      tag.add('human')\n",
    "      tag.add('people')\n",
    "\n",
    "  if q_num >=2 :\n",
    "    # Question 1\n",
    "    question_1 = \"What is the color of the photo?\"\n",
    "    inputs = processor_vqa(raw_image, question_1, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=3 :\n",
    "    # Question 8\n",
    "    question_8 = \"What is the context on image?\"\n",
    "    inputs = processor_vqa(raw_image, question_8, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "  if q_num >=4 :\n",
    "    # Question 4\n",
    "    question_4 = \"What is the image all about?\"\n",
    "    inputs = processor_vqa(raw_image, question_4, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=5 :\n",
    "    # Question 3\n",
    "    question_3 = \"What is the objects of the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_3, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=6 :\n",
    "    # Question 2\n",
    "    question_2 = \"What is the setting of the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_2, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "  if q_num >=7 :\n",
    "    # Question 10\n",
    "    question_10 = \"Is there animal in the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_10, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    result = processor_vqa.decode(out[0], skip_special_tokens=True)\n",
    "    if result == 'yes':\n",
    "      tag.add('animal')\n",
    "  if q_num >=8 :\n",
    "    # Question 11\n",
    "    question_11 = \"Is there building in the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_11, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    result = processor_vqa.decode(out[0], skip_special_tokens=True)\n",
    "    if result == 'yes':\n",
    "      tag.add('building')\n",
    "\n",
    "\n",
    "  if q_num >=9 :\n",
    "    # Question 5\n",
    "    question_5 = \"What is the cultural or geographics context of the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_5, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=10 :\n",
    "    # Question 6\n",
    "    question_6 = \"What is the overall composition of the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_6, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=11 :\n",
    "    # Question 7\n",
    "    question_7 = \"What decade the image come from?\"\n",
    "    inputs = processor_vqa(raw_image, question_7, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    tag.add(processor_vqa.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "  if q_num >=12 :\n",
    "    # Question 12\n",
    "    question_12 = \"Is there vehical in the image?\"\n",
    "    inputs = processor_vqa(raw_image, question_12, return_tensors=\"pt\")\n",
    "    out = model_vqa.generate(**inputs)\n",
    "    result = processor_vqa.decode(out[0], skip_special_tokens=True)\n",
    "    if result == 'yes':\n",
    "      tag.add('vehical')\n",
    "\n",
    "  tag.discard(\"none\")\n",
    "\n",
    "  return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtUKvqUmhdni"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open('blip_model_vqa.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Load the processor\n",
    "with open('blip_processor_vqa.pkl', 'rb') as f:\n",
    "    loaded_processor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sJfEs2yFlBAf"
   },
   "outputs": [],
   "source": [
    "url='https://act.accesstomemory.org/uploads/r/null/8/8/d/88d2340c8007d86da6026067defbc35bd3dc98a3a11a3da0ba3aa02efe84f627/Canberra_Fire_Brigade_1924_Hotchkiss_141.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tymx6rIxfsy0",
    "outputId": "1a18e2d3-fd13-478a-daa7-1503ee0b45b5"
   },
   "outputs": [],
   "source": [
    "#number can choose up to 12\n",
    "tag_generate(url,loaded_model,loaded_processor,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "0GctYUt_IK1E",
    "outputId": "7eb6d4f7-1fce-4b6e-9374-bcf11fd5317b"
   },
   "outputs": [],
   "source": [
    "raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_mGyEi2I8l-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('blip_model_vqa.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the processor\n",
    "with open('blip_processor_vqa.pkl', 'wb') as f:\n",
    "    pickle.dump(processor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdXEqAnNO7yk",
    "outputId": "a5dc5666-9ecd-440f-fcc1-7b652f2f1fe0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQfuUqPCPbSd"
   },
   "outputs": [],
   "source": [
    "!cp blip_model_vqa.pkl /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBvAdT-YPlAu"
   },
   "outputs": [],
   "source": [
    "!cp blip_processor_vqa.pkl /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_IKn3xpPoFS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
